{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73986b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bda53bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rajusubba/Documents/End-to-End MLOps/customer-churn-project'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bea05e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rajusubba/Documents/End-to-End MLOps/customer-churn-project'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/rajusubba/Documents/End-to-End MLOps/customer-churn-project\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08251a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    \"\"\"Configuration for data ingestion\"\"\"\n",
    "    # Where ingestion artifacts will be stored\n",
    "    root_dir: Path\n",
    "    \n",
    "    #Source type: \"postgres\" \n",
    "    source_type: str\n",
    "    \n",
    "    # Postgres connection details\n",
    "    host: str\n",
    "    port: int\n",
    "    database: str\n",
    "    user: str\n",
    "    \n",
    "    #Environment variable name for password\n",
    "    password_env: Optional[str] = None\n",
    "    \n",
    "    #Data source inside Postgres\n",
    "    schema: str = \"public\"\n",
    "    table: Optional[str] = None\n",
    "    query: Optional[str] = None\n",
    "    \n",
    "    #Export of raw snapshot\n",
    "    export_files: Optional[Path] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59e583ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG PATH: /Users/rajusubba/Documents/End-to-End MLOps/customer-churn-project/config/config.yaml\n",
      "EXISTS: True\n",
      "SIZE: 0\n",
      "CONTENT PREVIEW:\n",
      " ''\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"config/config.yaml\").resolve()\n",
    "print(\"CONFIG PATH:\", p)\n",
    "print(\"EXISTS:\", p.exists())\n",
    "print(\"SIZE:\", p.stat().st_size if p.exists() else None)\n",
    "print(\"CONTENT PREVIEW:\\n\", repr(p.read_text()[:300]) if p.exists() else \"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7c33698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.customerchurn.constants import *\n",
    "from src.customerchurn.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da656704",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_file_path = CONFIG_FILE_PATH,\n",
    "                 params_file_path = PARAMS_FILE_PATH,\n",
    "                 schema_file_path = SCHEMA_FILE_PATH,\n",
    "                 ):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        self.schema = read_yaml(schema_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        \n",
    "        config = self.config.data_ingestion\n",
    "        print(\"config.export:\", config.get(\"export\"))\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        pg = config.postgres  # <- IMPORTANT: nested config\n",
    "\n",
    "        export_files = None\n",
    "        if config.get(\"export\") and config.export.get(\"enabled\", False):\n",
    "            export_files = Path(config.export.output_file)\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            source_type=config.source_type,\n",
    "\n",
    "            host=pg.host,\n",
    "            port=int(pg.port),\n",
    "            database=pg.database,\n",
    "            user=pg.user,\n",
    "            password_env=pg.get(\"password_env\"),\n",
    "\n",
    "            schema=pg.get(\"schema\", \"public\"),\n",
    "            table=pg.get(\"table\"),\n",
    "            query=pg.get(\"query\"),\n",
    "\n",
    "            export_files=export_files,\n",
    "        )\n",
    "\n",
    "        return data_ingestion_config\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f63a493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG PATH: /Users/rajusubba/Documents/End-to-End MLOps/customer-churn-project/config/config.yaml\n",
      "EXISTS: True\n",
      "SIZE: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"config/config.yaml\").resolve()\n",
    "print(\"CONFIG PATH:\", p)\n",
    "print(\"EXISTS:\", p.exists())\n",
    "print(\"SIZE:\", p.stat().st_size if p.exists() else None)\n",
    "print(p.read_text()[:500] if p.exists() else \"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34374b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.customerchurn.logging.logger import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "826a8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def ingest_data(self) -> pd.DataFrame:\n",
    "        if self.config.source_type != \"postgres\":\n",
    "            raise ValueError(f\"Unsupported source type: {self.config.source_type}\")\n",
    "\n",
    "        password = os.getenv(self.config.password_env) if self.config.password_env else None\n",
    "\n",
    "        query = self.config.query\n",
    "        if not query:\n",
    "            if not self.config.table:\n",
    "                raise ValueError(\"Either 'query' or 'table' must be provided for postgres source.\")\n",
    "            query = f\"SELECT * FROM {self.config.schema}.{self.config.table};\"\n",
    "\n",
    "        with psycopg2.connect(\n",
    "            host=self.config.host,\n",
    "            port=self.config.port,\n",
    "            database=self.config.database,\n",
    "            user=self.config.user,\n",
    "            password=password,\n",
    "        ) as conn:\n",
    "            df = pd.read_sql_query(query, conn)\n",
    "\n",
    "        logging.info(f\"Data ingested successfully with shape: {df.shape}\")\n",
    "\n",
    "        if self.config.export_files:\n",
    "            self.config.export_files.parent.mkdir(parents=True, exist_ok=True)\n",
    "            df.to_csv(self.config.export_files, index=False)\n",
    "            logging.info(f\"Raw snapshot exported to {self.config.export_files}\")\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bddf28fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-03 13:36:05,671: INFO: common: YAML file src/customerchurn/config/config.yaml loaded successfully.]\n",
      "[2026-02-03 13:36:05,672: INFO: common: YAML file params.yaml loaded successfully.]\n",
      "[2026-02-03 13:36:05,674: INFO: common: YAML file schema.yaml loaded successfully.]\n",
      "[2026-02-03 13:36:05,674: INFO: common: Directory created at: artifacts]\n",
      "config.export: {'enabled': True, 'output_file': 'artifacts/data_ingestion/raw_snapshot.csv'}\n",
      "[2026-02-03 13:36:05,675: INFO: common: Directory created at: artifacts/data_ingestion]\n",
      "export_files = artifacts/data_ingestion/raw_snapshot.csv\n",
      "root_dir = artifacts/data_ingestion\n",
      "[2026-02-03 13:36:05,731: INFO: 4280944749: Data ingested successfully with shape: (10000, 13)]\n",
      "[2026-02-03 13:36:05,760: INFO: 4280944749: Raw snapshot exported to artifacts/data_ingestion/raw_snapshot.csv]\n",
      "Loaded shape: (10000, 13)\n",
      "   customerid   surname  creditscore geography  gender  age  tenure  \\\n",
      "0    15634602  Hargrave          619    France  Female   42       2   \n",
      "1    15647311      Hill          608     Spain  Female   41       1   \n",
      "2    15619304      Onio          502    France  Female   42       8   \n",
      "3    15701354      Boni          699    France  Female   39       1   \n",
      "4    15737888  Mitchell          850     Spain  Female   43       2   \n",
      "\n",
      "     balance  numofproducts  hascrcard  isactivemember  estimatedsalary  \\\n",
      "0       0.00              1          1               1        101348.88   \n",
      "1   83807.86              1          0               1        112542.58   \n",
      "2  159660.80              3          1               0        113931.57   \n",
      "3       0.00              2          0               0         93826.63   \n",
      "4  125510.82              1          1               1         79084.10   \n",
      "\n",
      "   exited  \n",
      "0       1  \n",
      "1       0  \n",
      "2       1  \n",
      "3       0  \n",
      "4       0  \n",
      "[2026-02-03 13:36:05,762: INFO: 522963440: Data ingestion completed successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/qbk1304d7p3fppsg4n9dxvvh0000gn/T/ipykernel_18705/4280944749.py:29: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    data_ingestion_config = config_manager.get_data_ingestion_config()\n",
    "    print(\"export_files =\", data_ingestion_config.export_files)\n",
    "    print(\"root_dir =\", data_ingestion_config.root_dir)\n",
    "    \n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    df = data_ingestion.ingest_data()\n",
    "    print(\"Loaded shape:\", df.shape)\n",
    "    print(df.head())\n",
    "    \n",
    "    logging.info(\"Data ingestion completed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.exception(\"Data ingestion failed.\")\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
